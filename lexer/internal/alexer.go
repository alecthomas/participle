// Code generated by Participle. DO NOT EDIT.
package internal

import (
	"io"
	"regexp/syntax"
	"strings"
	"unicode/utf8"

	"github.com/alecthomas/participle/v2"
	"github.com/alecthomas/participle/v2/lexer"
)

var _ syntax.Op
var _ = utf8.DecodeRune

var GeneratedALexer lexer.Definition = lexerGeneratedADefinitionImpl{}

type lexerGeneratedADefinitionImpl struct{}

func (lexerGeneratedADefinitionImpl) Symbols() map[string]lexer.TokenType {
	return map[string]lexer.TokenType{
		"A":          -2,
		"EOF":        -1,
		"Ident":      -3,
		"whitespace": -4,
	}
}

func (lexerGeneratedADefinitionImpl) LexString(filename string, s string) (lexer.Lexer, error) {
	return &lexerGeneratedAImpl{
		s: s,
		pos: lexer.Position{
			Filename: filename,
			Line:     1,
			Column:   1,
		},
		states: []lexerGeneratedAState{lexerGeneratedAState{name: "Root"}},
	}, nil
}

func (d lexerGeneratedADefinitionImpl) LexBytes(filename string, b []byte) (lexer.Lexer, error) {
	return d.LexString(filename, string(b))
}

func (d lexerGeneratedADefinitionImpl) Lex(filename string, r io.Reader) (lexer.Lexer, error) {
	s := &strings.Builder{}
	_, err := io.Copy(s, r)
	if err != nil {
		return nil, err
	}
	return d.LexString(filename, s.String())
}

type lexerGeneratedAState struct {
	name   string
	groups []string
}

type lexerGeneratedAImpl struct {
	s      string
	p      int
	pos    lexer.Position
	states []lexerGeneratedAState
}

func (l *lexerGeneratedAImpl) Next() (lexer.Token, error) {
	if l.p == len(l.s) {
		return lexer.EOFToken(l.pos), nil
	}
	var (
		state  = l.states[len(l.states)-1]
		groups []int
		sym    lexer.TokenType
	)
	switch state.name {
	case "Root":
		if match := matchGeneratedAA(l.s, l.p); match[1] != 0 {
			sym = -2
			groups = match[:]
		} else if match := matchGeneratedAIdent(l.s, l.p); match[1] != 0 {
			sym = -3
			groups = match[:]
		} else if match := matchGeneratedAwhitespace(l.s, l.p); match[1] != 0 {
			sym = -4
			groups = match[:]
		}
	}
	if groups == nil {
		sample := []rune(l.s[l.p:])
		if len(sample) > 16 {
			sample = append(sample[:16], []rune("...")...)
		}
		return lexer.Token{}, participle.Errorf(l.pos, "invalid input text %q", sample)
	}
	pos := l.pos
	span := l.s[groups[0]:groups[1]]
	l.p = groups[1]
	l.pos.Advance(span)
	return lexer.Token{
		Type:  sym,
		Value: span,
		Pos:   pos,
	}, nil
}

func (l *lexerGeneratedAImpl) sgroups(match []int) []string {
	sgroups := make([]string, len(match)/2)
	for i := 0; i < len(match)-1; i += 2 {
		sgroups[i/2] = l.s[l.p+match[i] : l.p+match[i+1]]
	}
	return sgroups
}

// a
func matchGeneratedAA(s string, p int) (groups [2]int) {
	if p < len(s) && s[p] == 'a' {
		groups[0] = p
		groups[1] = p + 1
	}
	return
}

// [0-9A-Z_a-z]+
func matchGeneratedAIdent(s string, p int) (groups [2]int) {
	// [0-9A-Z_a-z] (CharClass)
	l0 := func(s string, p int) int {
		if len(s) <= p {
			return -1
		}
		rn := s[p]
		switch {
		case rn >= '0' && rn <= '9':
			return p + 1
		case rn >= 'A' && rn <= 'Z':
			return p + 1
		case rn == '_':
			return p + 1
		case rn >= 'a' && rn <= 'z':
			return p + 1
		}
		return -1
	}
	// [0-9A-Z_a-z]+ (Plus)
	l1 := func(s string, p int) int {
		if p = l0(s, p); p == -1 {
			return -1
		}
		for len(s) > p {
			if np := l0(s, p); np == -1 {
				return p
			} else {
				p = np
			}
		}
		return p
	}
	np := l1(s, p)
	if np == -1 {
		return
	}
	groups[0] = p
	groups[1] = np
	return
}

// [\t-\n\f-\r ]+
func matchGeneratedAwhitespace(s string, p int) (groups [2]int) {
	// [\t-\n\f-\r ] (CharClass)
	l0 := func(s string, p int) int {
		if len(s) <= p {
			return -1
		}
		rn := s[p]
		switch {
		case rn >= '\t' && rn <= '\n':
			return p + 1
		case rn >= '\f' && rn <= '\r':
			return p + 1
		case rn == ' ':
			return p + 1
		}
		return -1
	}
	// [\t-\n\f-\r ]+ (Plus)
	l1 := func(s string, p int) int {
		if p = l0(s, p); p == -1 {
			return -1
		}
		for len(s) > p {
			if np := l0(s, p); np == -1 {
				return p
			} else {
				p = np
			}
		}
		return p
	}
	np := l1(s, p)
	if np == -1 {
		return
	}
	groups[0] = p
	groups[1] = np
	return
}
