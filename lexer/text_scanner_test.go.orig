package lexer_test

import (
	"strings"
	"testing"
	"text/scanner"

	"github.com/alecthomas/assert/v2"

	"github.com/alecthomas/participle/v2"
	"github.com/alecthomas/participle/v2/lexer"
)

func TestLexer(t *testing.T) {
<<<<<<< HEAD
	lex, err := lexer.Upgrade(lexer.LexString("", "hello world"))
	require.NoError(t, err)
	helloPos := lexer.Position{Offset: 0, Line: 1, Column: 1}
	worldPos := lexer.Position{Offset: 6, Line: 1, Column: 7}
	eofPos := lexer.Position{Offset: 11, Line: 1, Column: 12}
	require.Equal(t, lexer.Token{Type: scanner.Ident, Value: "hello", Pos: helloPos}, mustPeek(t, lex, 0))
	require.Equal(t, lexer.Token{Type: scanner.Ident, Value: "hello", Pos: helloPos}, mustPeek(t, lex, 0))
	require.Equal(t, lexer.Token{Type: scanner.Ident, Value: "hello", Pos: helloPos}, mustNext(t, lex))
	require.Equal(t, lexer.Token{Type: scanner.Ident, Value: "world", Pos: worldPos}, mustPeek(t, lex, 0))
	require.Equal(t, lexer.Token{Type: scanner.Ident, Value: "world", Pos: worldPos}, mustNext(t, lex))
	require.Equal(t, lexer.Token{Type: scanner.EOF, Value: "", Pos: eofPos}, mustPeek(t, lex, 0))
	require.Equal(t, lexer.Token{Type: scanner.EOF, Value: "", Pos: eofPos}, mustNext(t, lex))
}

func TestLexString(t *testing.T) {
	lex := lexer.LexString("", "\"hello world\"")
	token, err := lex.Next()
	require.NoError(t, err)
	require.Equal(t, token, lexer.Token{Type: scanner.String, Value: "\"hello world\"", Pos: lexer.Position{Line: 1, Column: 1}})
}

func TestLexSingleString(t *testing.T) {
	lex := lexer.LexString("", "`hello world`")
	token, err := lex.Next()
	require.NoError(t, err)
	require.Equal(t, lexer.Token{Type: scanner.RawString, Value: "`hello world`", Pos: lexer.Position{Line: 1, Column: 1}}, token)
	lex = lexer.LexString("", `'\U00008a9e'`)
	token, err = lex.Next()
	require.NoError(t, err)
	require.Equal(t, lexer.Token{Type: scanner.Char, Value: `'\U00008a9e'`, Pos: lexer.Position{Line: 1, Column: 1}}, token)
=======
	lexer, err := Upgrade(LexString("", "hello world"))
	assert.NoError(t, err)
	helloPos := Position{Offset: 0, Line: 1, Column: 1}
	worldPos := Position{Offset: 6, Line: 1, Column: 7}
	eofPos := Position{Offset: 11, Line: 1, Column: 12}
	assert.Equal(t, Token{Type: scanner.Ident, Value: "hello", Pos: helloPos}, mustPeek(t, lexer, 0))
	assert.Equal(t, Token{Type: scanner.Ident, Value: "hello", Pos: helloPos}, mustPeek(t, lexer, 0))
	assert.Equal(t, Token{Type: scanner.Ident, Value: "hello", Pos: helloPos}, mustNext(t, lexer))
	assert.Equal(t, Token{Type: scanner.Ident, Value: "world", Pos: worldPos}, mustPeek(t, lexer, 0))
	assert.Equal(t, Token{Type: scanner.Ident, Value: "world", Pos: worldPos}, mustNext(t, lexer))
	assert.Equal(t, Token{Type: scanner.EOF, Value: "", Pos: eofPos}, mustPeek(t, lexer, 0))
	assert.Equal(t, Token{Type: scanner.EOF, Value: "", Pos: eofPos}, mustNext(t, lexer))
}

func TestLexString(t *testing.T) {
	lexer := LexString("", "\"hello world\"")
	token, err := lexer.Next()
	assert.NoError(t, err)
	assert.Equal(t, token, Token{Type: scanner.String, Value: "\"hello world\"", Pos: Position{Line: 1, Column: 1}})
}

func TestLexSingleString(t *testing.T) {
	lexer := LexString("", "`hello world`")
	token, err := lexer.Next()
	assert.NoError(t, err)
	assert.Equal(t, Token{Type: scanner.RawString, Value: "`hello world`", Pos: Position{Line: 1, Column: 1}}, token)
	lexer = LexString("", `'\U00008a9e'`)
	token, err = lexer.Next()
	assert.NoError(t, err)
	assert.Equal(t, Token{Type: scanner.Char, Value: `'\U00008a9e'`, Pos: Position{Line: 1, Column: 1}}, token)
>>>>>>> 703c5a4 (A branch of Participle 2 using Go 1.18 generics.)
}

func TestNewTextScannerLexerDefault(t *testing.T) {
	type grammar struct {
		Text string `@String @Ident`
	}
<<<<<<< HEAD
	p, err := participle.Build(&grammar{}, participle.Lexer(lexer.NewTextScannerLexer(nil)), participle.Unquote())
	require.NoError(t, err)
	g := &grammar{}
	err = p.ParseString("", `"hello" world`, g)
	require.NoError(t, err)
	require.Equal(t, "helloworld", g.Text)
=======
	p, err := participle.Build[grammar](participle.Lexer(NewTextScannerLexer(nil)), participle.Unquote())
	assert.NoError(t, err)
	g, err := p.ParseString("", `"hello" world`)
	assert.NoError(t, err)
	assert.Equal(t, "helloworld", g.Text)
>>>>>>> 703c5a4 (A branch of Participle 2 using Go 1.18 generics.)
}

func TestNewTextScannerLexer(t *testing.T) {
	type grammar struct {
		Text string `(@String | @Comment | @Ident)+`
	}
<<<<<<< HEAD
	p, err := participle.Build(&grammar{}, participle.Lexer(lexer.NewTextScannerLexer(func(s *scanner.Scanner) {
=======
	p, err := participle.Build[grammar](participle.Lexer(NewTextScannerLexer(func(s *scanner.Scanner) {
>>>>>>> 703c5a4 (A branch of Participle 2 using Go 1.18 generics.)
		s.Mode &^= scanner.SkipComments
	})), participle.Unquote())
	assert.NoError(t, err)
	g, err := p.ParseString("", `"hello" /* comment */ world`)
	assert.NoError(t, err)
	assert.Equal(t, "hello/* comment */world", g.Text)
}

func BenchmarkTextScannerLexer(b *testing.B) {
	input := strings.Repeat("hello world 123 hello world 123", 100)
	r := strings.NewReader(input)
	b.ReportMetric(float64(len(input)), "B")
	b.ReportAllocs()
	for i := 0; i < b.N; i++ {
		lex, _ := lexer.TextScannerLexer.Lex("", r)
		for {
			token, _ := lex.Next()
			if token.Type == lexer.EOF {
				break
			}
		}
		_, _ = r.Seek(0, 0)
	}
}
